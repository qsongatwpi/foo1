{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpu_vs_cpu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songqsh/foo1/blob/master/src/gpu_vs_cpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-ZN7vQHtraF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TztwOCyI-amb",
        "colab_type": "text"
      },
      "source": [
        "__Goal__\n",
        "\n",
        "We compare the performance of GPU and CPU on the same task using pytorch\n",
        "\n",
        "__Rk__\n",
        "\n",
        "- Colab does not allow even bigger tensor calculation.\n",
        "- cpu time is 50 times of gpu time\n",
        "- parallel computing, but not all computing, makes gpu faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VisZFmlznuyR",
        "colab_type": "text"
      },
      "source": [
        "__Experiment1__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my7tXdfsnzbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10de52db-8e8f-4dc9-d63b-11e76f05a941"
      },
      "source": [
        "d = 10000\n",
        "\n",
        "start = time.perf_counter()\n",
        "A = np.random.rand(d,d).astype(np.float32)\n",
        "B = np.random.rand(d,d).astype(np.float32)\n",
        "C = A@B\n",
        "end = time.perf_counter()\n",
        "\n",
        "print('>>> elapsed cpu time is ' + str(end - start))\n",
        "\n",
        "\n",
        "start = time.perf_counter()\n",
        "A = torch.rand(d,d).cuda()\n",
        "B = torch.rand(d,d).cuda()\n",
        "C = A@B\n",
        "end = time.perf_counter()\n",
        "\n",
        "print('>>> elapsed gpu time is ' + str(end - start))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> elapsed cpu time is 31.55923078500001\n",
            ">>> elapsed gpu time is 5.901846424000013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1JzHsJnnzt8",
        "colab_type": "text"
      },
      "source": [
        "__Experiment2__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTwgAVNRH8WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim_ = 9\n",
        "len_ = 9\n",
        "size_ = torch.ones(dim_, dtype = torch.int8)*len_\n",
        "size_ = tuple(map(lambda x: x, size_))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJUO6rBozXc6",
        "colab_type": "code",
        "outputId": "2c97d81b-1f75-410b-d0a4-e4ed9c795d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#cpu\n",
        "\n",
        "tensor_1 = torch.randn(size_)\n",
        "#tensor_2 = torch.randn(size_)\n",
        "\n",
        "print('>>>go CPU')\n",
        "start_ = time.perf_counter()\n",
        "\n",
        "#tensor_3 = tensor_1 + tensor_2\n",
        "tensor_3 = torch.mul(tensor_1, tensor_1) + tensor_1\n",
        "print(tensor_3.sum()/tensor_3.nelement())\n",
        "\n",
        "end_ = time.perf_counter()\n",
        "print('>>>CPU elapsed time is ' + str(end_ - start_))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>go CPU\n",
            "tensor(1.0270)\n",
            ">>>CPU elapsed time is 2.5829453660000183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXFEQbz-y9sg",
        "colab_type": "code",
        "outputId": "e0f71e02-fcfb-4934-ab31-29cfd3b174dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#gpu\n",
        "\n",
        "tensor_gpu_1 = torch.randn(size_).cuda()\n",
        "#tensor_gpu_2 = torch.randn(size_).cuda()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print('>>>go GPU')\n",
        "start_ = time.perf_counter()\n",
        "\n",
        "#tensor_gpu_3 = tensor_gpu_1 + tensor_gpu_2\n",
        "tensor_gpu_3 = torch.mul(tensor_gpu_1, tensor_gpu_1) + tensor_gpu_1\n",
        "print(tensor_gpu_3.sum()/tensor_gpu_3.nelement())\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "end_ = time.perf_counter()\n",
        "print('>>>GPU elapsed time is ' + str(end_ - start_))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>go GPU\n",
            "tensor(0.9999, device='cuda:0')\n",
            ">>>GPU elapsed time is 0.04104163299999186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5OF5o8dFhtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}