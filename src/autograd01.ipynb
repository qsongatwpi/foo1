{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autograd01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songqsh/foo1/blob/master/src/autograd01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjK7R6MS60WK",
        "colab_type": "text"
      },
      "source": [
        "# Higher order derivatives with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca0yd39a6p81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwEAEcaN7a1B",
        "colab_type": "text"
      },
      "source": [
        "## The derivatives of 1-1 mapping\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkk3WVwV7G1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9b142908-5c8e-4743-b5af-c07a16249397"
      },
      "source": [
        "#The 1-1 mapping to take derivative\n",
        "\n",
        "#f = lambda x: x**3 + 2*x\n",
        "net = nn.Linear(1, 1)\n",
        "for p in net.parameters():\n",
        "  print(p)\n",
        "\n",
        "f = lambda x: net(x) + x**2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.0168]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.7037], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6IRX691CPSz",
        "colab_type": "text"
      },
      "source": [
        "### At a point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIWX8KTz7P9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "11b5d22c-54a4-4450-e3c0-7d4c1129de83"
      },
      "source": [
        "#At one point\n",
        "x = torch.tensor([2], dtype=torch.float, requires_grad=True)\n",
        "y = f(x) #function value\n",
        "print('y', y)\n",
        "\n",
        "y_g1 = grad(y, x, create_graph=True)[0] #first order\n",
        "print('y_g1', y_g1)\n",
        "\n",
        "y_g2 = grad(y_g1, x, create_graph=True)[0] #second order\n",
        "print('y_g2', y_g2)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y tensor([3.3299], grad_fn=<AddBackward0>)\n",
            "y_g1 tensor([4.0168], grad_fn=<AddBackward0>)\n",
            "y_g2 tensor([2.], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK4vglrMCHeb",
        "colab_type": "text"
      },
      "source": [
        "### At an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcwLy1pq-OB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "912d2b00-5637-436f-89ad-ac10450acfda"
      },
      "source": [
        "#At an array\n",
        "x_arr = torch.tensor([1, 2], dtype=torch.float, requires_grad=True).reshape(2,1)\n",
        "for x in x_arr:\n",
        "  y = f(x) #function value\n",
        "  print('y', y) \n",
        "\n",
        "  y_g1 = grad(y, x, create_graph=True)[0] #first order\n",
        "  print('y_g1', y_g1)\n",
        "  \n",
        "  y_g2 = grad(y_g1, x, create_graph=True)[0] #second order\n",
        "  print('y_g2', y_g2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y tensor([0.3131], grad_fn=<AddBackward0>)\n",
            "y_g1 tensor([2.0168], grad_fn=<AddBackward0>)\n",
            "y_g2 tensor([2.], grad_fn=<MulBackward0>)\n",
            "y tensor([3.3299], grad_fn=<AddBackward0>)\n",
            "y_g1 tensor([4.0168], grad_fn=<AddBackward0>)\n",
            "y_g2 tensor([2.], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t70vtzOsJsMA",
        "colab_type": "text"
      },
      "source": [
        "# The derivatives of 2-1 mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpCJginMBZ_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "daa5f76a-1ead-46fd-c6df-235bd1a3d9d1"
      },
      "source": [
        "#The 2-1 mapping to take derivative\n",
        "\n",
        "net = nn.Linear(2, 1)\n",
        "for p in net.parameters():\n",
        "  print(p)\n",
        "\n",
        "f = lambda x: net(x) + torch.sum(x**3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.5842,  0.5356]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.6364], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dWe0gMJKKFS",
        "colab_type": "text"
      },
      "source": [
        "### At a point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYvFqM6IKE2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "27090647-54bd-4378-bbdf-12f428ac4d00"
      },
      "source": [
        "x = torch.tensor([0,1], dtype=torch.float, requires_grad=True)\n",
        "y = f(x) #function value\n",
        "print('y', y)\n",
        "\n",
        "y_g1 = grad(y, x, create_graph=True)[0] #gradient\n",
        "print('y_g1', y_g1)\n",
        "\n",
        "y_g2_0 = grad(y_g1[0], x, create_graph=True, allow_unused=True)[0] #Hessian line-0\n",
        "print('y_g2_0', y_g2_0)\n",
        "\n",
        "\n",
        "y_g2_1 = grad(y_g1[1], x, create_graph=True, allow_unused=True)[0] #Hessian line-1\n",
        "print('y_g2_1', y_g2_1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y tensor([0.8992], grad_fn=<AddBackward0>)\n",
            "y_g1 tensor([-0.5842,  3.5356], grad_fn=<AddBackward0>)\n",
            "y_g2_0 tensor([0., 0.], grad_fn=<MulBackward0>)\n",
            "y_g2_1 tensor([0., 6.], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ9rh1kzKVU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}