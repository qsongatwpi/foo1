{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autograd01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songqsh/foo1/blob/master/src/autograd01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjK7R6MS60WK",
        "colab_type": "text"
      },
      "source": [
        "# Higher order derivatives with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca0yd39a6p81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwEAEcaN7a1B",
        "colab_type": "text"
      },
      "source": [
        "## The derivatives of 1-1 mapping\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkk3WVwV7G1d",
        "colab_type": "code",
        "outputId": "fd048209-ad50-48cf-a519-4d5196e119ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#The 1-1 mapping to take derivative\n",
        "\n",
        "#f = lambda x: x**3 + 2*x\n",
        "net = nn.Linear(1, 1)\n",
        "for p in net.parameters():\n",
        "  print(p)\n",
        "\n",
        "f = lambda x: net(x) + 0.*x**2 "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.1365]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1587], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6IRX691CPSz",
        "colab_type": "text"
      },
      "source": [
        "### At a point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIWX8KTz7P9V",
        "colab_type": "code",
        "outputId": "c7af3d70-9be7-40dc-c912-d96db1a692df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#At one point\n",
        "x = torch.tensor([2], dtype=torch.float, requires_grad=True)\n",
        "y = f(x) #function value\n",
        "print('y', y)\n",
        "\n",
        "y_g1 = grad(y, x, create_graph=True)[0] #first order\n",
        "print('y_g1', y_g1)\n",
        "\n",
        "y_g2 = grad(y_g1, x, create_graph=True)[0] #second order\n",
        "print('y_g2', y_g2)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y tensor([0.1143], grad_fn=<AddBackward0>)\n",
            "y_g1 tensor([0.1365], grad_fn=<AddBackward0>)\n",
            "y_g2 tensor([0.], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK4vglrMCHeb",
        "colab_type": "text"
      },
      "source": [
        "### At an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcwLy1pq-OB3",
        "colab_type": "code",
        "outputId": "3bcfe576-762b-4f86-f37d-a33bc3d88116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#At an array\n",
        "x_arr = torch.tensor([1, 2], dtype=torch.float, requires_grad=True).reshape(2,1)\n",
        "for x in x_arr:\n",
        "  y = f(x) #function value\n",
        "  print('y', y) \n",
        "\n",
        "  y_g1 = grad(y, x, create_graph=True)[0] #first order\n",
        "  print('y_g1', y_g1)\n",
        "  \n",
        "  y_g2 = grad(y_g1, x, create_graph=True)[0] #second order\n",
        "  print('y_g2', y_g2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y tensor([-0.0222], grad_fn=<AddBackward0>)\n",
            "y_g1 tensor([0.1365], grad_fn=<AddBackward0>)\n",
            "y_g2 tensor([0.], grad_fn=<MulBackward0>)\n",
            "y tensor([0.1143], grad_fn=<AddBackward0>)\n",
            "y_g1 tensor([0.1365], grad_fn=<AddBackward0>)\n",
            "y_g2 tensor([0.], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t70vtzOsJsMA",
        "colab_type": "text"
      },
      "source": [
        "# The derivatives of 2-1 mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpCJginMBZ_Q",
        "colab_type": "code",
        "outputId": "30f8002d-38a6-4386-a0d4-34e7c9bb41b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#The 2-1 mapping to take derivative\n",
        "\n",
        "net = nn.Linear(2, 1)\n",
        "for p in net.parameters():\n",
        "  print(p)\n",
        "\n",
        "f = lambda x: net(x) + torch.sum(x**3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.6644, -0.2759]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.3242], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dWe0gMJKKFS",
        "colab_type": "text"
      },
      "source": [
        "### At a point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYvFqM6IKE2Z",
        "colab_type": "code",
        "outputId": "60ec6e4c-d4d0-4340-fb53-9187ed17d888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x = torch.tensor([0,1], dtype=torch.float, requires_grad=True)\n",
        "y = f(x) #function value\n",
        "print('y', y)\n",
        "\n",
        "y_g1 = grad(y, x, create_graph=True)[0] #gradient\n",
        "print('y_g1', y_g1)\n",
        "\n",
        "y_g2_0 = grad(y_g1[0], x, create_graph=True, allow_unused=True)[0] #Hessian line-0\n",
        "print('y_g2_0', y_g2_0)\n",
        "\n",
        "\n",
        "y_g2_1 = grad(y_g1[1], x, create_graph=True, allow_unused=True)[0] #Hessian line-1\n",
        "print('y_g2_1', y_g2_1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y tensor([0.3998], grad_fn=<AddBackward0>)\n",
            "y_g1 tensor([0.6644, 2.7241], grad_fn=<AddBackward0>)\n",
            "y_g2_0 tensor([0., 0.], grad_fn=<MulBackward0>)\n",
            "y_g2_1 tensor([0., 6.], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ9rh1kzKVU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}