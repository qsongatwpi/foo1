# foo1

- linear algebra with tensorflow - [ipynb](src/linalg_tf.ipynb)
- linear regression: linear algebra approach and machine learning approach - [ipynb](src/linreg.ipynb)
- minimize a smooth function by pytorch optimizer - [ipynb](src/min_fun.ipynb)
- p: linear regression with pytorch - [ipynb](src/linreg_torch_v01.ipynb)
- learning quadratic function by nn - [ipynb](src/Copy_of_Copy_of_learning_quadratic_function_by_nn.ipynb)
- learning by nn with normalization - [ipynb](src/learning_quadratic_function_by_nn_normalize.ipynb)
- learn bsm - [ipynb](src/nn_learn_bsm_formula.ipynb)
- fitting two points by nn - [ipynb](src/fitting-two-pts-by-nn.ipynb)
- fitting three points by nn - [ipynb](src/fit-3-pts-by-nn.ipynb)
- SB18-Example 4.1-Gridworld -[ipynb](src/sb18-exm-4-1.ipynb)
- gambbler's problem: reinforcement learning - [ipynb](src/gambler_v01.ipynb)
- MDP from HJB - [pdf](doc/191206HJB.pdf) - [ipynb](src/hjb_mdp_01.ipynb)
- 1d MDP with q-table - [ipynb](src/mdp_1d_qtable.ipynb)
- cliff walking: Sarsa/Q-learning - [ipynb](src/cliff_v01.ipynb)
- Backward in time dynamic programing on HJB with Cauchy data - [ipynb](src/dp_hjb_cauchy.ipynb)
- 1-d dynamic programing on HJB with Cauchy data (to check above) - [ipynb](src/dp_hjb_cauchy_ex1d.ipynb)
- Semi-explicit solution/DPP on 1-d dp-hjb-cauchy (to check above) -[ipynb](src/dp_hjb_1d_v1.ipynb)
- value iteration on 1d HJB with dirichlet data - [ipynb](src/value_iter_dirichlet_1d_v01.ipynb)
- p: value iteration on 1d HJB with dirichlet data with upwind scheme does not work - [ipynb](src/value_iter_hjb_upwind.ipynb)
- q-learning approach on  1d HJB with dirichlet data - [ipynb](src/q_learning_dirichlet_1d.ipynb)
- gpu vs cpu performance by pytorch tensor calculation - [ipynb](src/gpu_vs_cpu.ipynb)
- gpu vs cpu performance on MDP - [ipynb](src/gpu2cpu.ipynb)
- Pytorch: Autograd for higher order - [ipynb](src/autograd01.ipynb)
- First order ODE by fixed point theorem - [ipynb](src/ode01.ipynb)
- Second order ODE by FPT - [ipynb](src/ode02.ipynb)


